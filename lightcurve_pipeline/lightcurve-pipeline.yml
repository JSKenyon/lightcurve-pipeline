#!/usr/bin/env -S stimela run

_include:
  - lightcurve-cabs.yml

## this augments the standard 'opts' config section to tweak logging settings
opts:
  log:
    dir: logs/log-{config.run.datetime}
    name: log-{info.fqname}
    nest: 2
    symlink: log
  backend:
    select: singularity
    rlimits:
      NOFILE: 100000  # set high limit on number of open files

lightcurve-pipeline:
  name: lightcurve-pipeline
  info: "Generic pipeline for extracting lightcurves from interferometer data."

  assign:
    dir-out: '{recipe.dirs.base}/{recipe.dirs.sub}{recipe.output-suffix}'  # output products go here
    image-prefix: '{recipe.dir-out}/im{info.suffix}{recipe.variant}/im{info.suffix}{recipe.variant}'  # prefix for image names at each step
    log.dir: '{recipe.dir-out}/logs/log-{config.run.datetime}'  # put logs into output dir
    # some more directory assignments
    dirs:
      ms: msdir  # MSs live here
      temp: "{config.run.env.HOME}/tmp"  # temp files go here
      base: /home/kenyon/ATA_experiments/lightcurve_extraction/working_dir  # base project directory -- directory of recipe by default

    # _chan1x: =recipe.chan1 - 1       # end channel, inclusive -- helper variable to form CASA spw
    casa-spw: 0 #"0:{recipe.chan0}~{recipe._chan1x}"  # CASA spw parameter

    # extra lightcurve suffix, added if convolving
    lc-suffix: =IF(recipe.convolve.arcsec or recipe.convolve.time, "-{recipe.convolve.time:.0f}s-{recipe.convolve.arcsec:.0f}asec", "")

  assign_based_on:
    _include: datasets.yml

  inputs:
    obs:
      choices: [ATA_test]
      info: "Selects observation, see datasets.yml for list of observations."
      default: ATA_test
    output-suffix:
      dtype: str
      default: ''
    variant:
      dtype: str
      default: ''
    htc_cadence:
      dtype: int
      default: 1
    htc_size:
      dtype: int
      default: 512
    htc_scale:
      dtype: str
      default: '{recipe.pixel_scale}'
    htc_weight:
      dtype: str
      default: natural
    convolve:
      arcsec:
        dtype: float
        default: 0
      time:
        dtype: float
        default: 120
    mad_flag:
      dtype: bool
      default: false
      aliases:
        - (quartical).mad_flags.enable
    publish-plots:
      dtype: bool
      default: false
    publish-plot-title:
      default: 'Observation {recipe.obs}: peak $ {{peak_ujy:.0f}}\pm{{peak_std_ujy:.0f}} $ uJy'

  aliases:
    ms:
      - (wsclean).ms
      - (quartical).input_ms.path
    weight:
      - (wsclean).weight
      - (wsclean_pol).weight
    minuv-l:
      - (wsclean).minuv-l
    taper-inner-tukey:
      - (wsclean).taper-inner-tukey

  steps:
    flag-save:
      info: |
        Create a backup of the original flags on the dataset. This step is only
        run when the init tag is selected.
      tags: [init, never]
      cab: casa.flagman
      params:
        ms: =recipe.ms
        mode: save
        versionname: =recipe.initial-flag-version

    save-ms-info:
      info: |
        Run some custom python code to extract some useful metadata
        from the dataset
      tags: [always]
      cab: save-ms-info
      skip_if_outputs: exist
      params:
        ms: =recipe.ms
        ms-info-file: '{recipe.dir-out}/{recipe.ms}.yml'

    ms-info:
      info: |
        Load the file generated by save-ms-info so that it can be used by later
        recipe steps. Note that this step must be run for any subsequent steps
        which use its outputs to work.
      tags: [always]
      cab: load-ms-info
      params:
        ms-info-file: =steps.save-ms-info.ms-info-file

    flag-reset:
      info: |
        Restore the original flags to the dataset. The flag-save step must have
        been run once for this step to work.
      cab: casa.flagman
      params:
        ms: =recipe.ms
        mode: restore
        versionname: =recipe.initial-flag-version

    image-1:
      info: |
        Image and deconvolve the data using wsclean. Masking and thresholding
        are handled automatically by wsclean. This may not work in all cases.
      _use: lib.steps.wsclean.image_column
      params:
        column: DATA  # Start from the contents of the DATA column.

    mask-1:
      info: |
        Make a mask for the field using breizorro.
      recipe: make_masks
      params:
        restored-image: "{previous.restored.mfs}"
        prefix: "{previous.prefix}"

    flagsummary-1:
      info: |
        Use casa to generate a summary of the flags on the dataset.
      cab: casa.flagsummary
      params:
        ms: =recipe.ms
        spw: =recipe.casa-spw

    predict-1:
      info: |
        Use wsclean to write the visibilities associated with the model to the
        MODEL_DATA column.
      _use: lib.steps.wsclean.predict
      params:
        ms: '{recipe.ms}'
        prefix: '{steps.image-1.prefix}'
        nchan: '{steps.image-1.nchan}'

    selfcal-1:
      info: |
        Use quartical to perform basic selfcal. Solves for a delay and phase
        term per scan. Note that the selfcal step may require tuning based
        on the field and instrument in question.
      _use: lib.steps.quartical.k

    flagsummary-2:
      info: |
        Use casa to generate a summary of the flags on the dataset.
      cab: casa.flagsummary
      params:
        ms: =recipe.ms
        spw: =recipe.casa-spw

    image-2:
      info: |
        Image and deconvolve the selfcal corrected data using wsclean and a
        fits mask.
      _use: lib.steps.wsclean.image_column
      params:
        fits-mask: =steps.mask-1.mask
        auto-threshold: 1

    source-catalog:
      info: |
        Extract a source catalogue from a restored image using pybdsf.
      cab: bdsf.catalog
      params:
        image: =steps.image-2.restored.mfs
        thresh_pix: 4
        thresh_isl: 3
        rms_box: [20,5]
        rms_map: false
        catalog_format: ascii
        outfile_gaul: =STRIPEXT(current.image) + '.gaul'
        outfile_srl: =STRIPEXT(current.image) + '.srl'

    make-master-catalog:
      info: |
        Create a single master catalog in .ecsv format. This can be used to
        merge image-based pybdsf catalogues with other catalogues of known or
        interesting sources.
      cab: make-master-catalog
      params:
        master_catalog: =recipe.dir-out + '/mastercat.ecsv'
        ra0: '{steps.ms-info.field_ra_deg}deg'
        dec0: '{steps.ms-info.field_dec_deg}deg'
        max_radius_deg: 1.5
        catalogs:
          bdsf: [=previous.outfile_srl, 6, main]

    predict-2:
      info: |
        Use wsclean to write the visibilities associated with the model to the
        MODEL_DATA column.
      _use: lib.steps.wsclean.predict
      params:
        ms: '{recipe.ms}'
        prefix: =steps.image-2.prefix
        nchan: =steps.image-2.nchan

    add-corrected-data:
      info: |
        Use casa to add the CORRECTED_DATA column if it does not exist.
      cab: msutils.addcol
      params:
        msname: =recipe.ms
        colname: CORRECTED_DATA

    subtract-model:
      info: |
        Subtract the model visibilities from the corrected data to produce the
        corrected residuals.
      cab: taql.update
      params:
        ms: "{recipe.ms}"
        commands: =LIST("set", "CORRECTED_DATA={steps.image-2.column}-MODEL_DATA")

    htc-image-1:
      info: |
        Use wsclean to create a series of images corresponding to time
        intervals. Ideally, this will be an image per unique time, but this
        resolution can be controlled using the htc_cadence parameter to
        decrease computational expense at the cost of time resolution.
      _use: lib.steps.wsclean.dirty
      params:
        column: CORRECTED_DATA
        prefix: =DIRNAME(recipe.image-prefix) + '-cad{recipe.htc_cadence}/images/cad{recipe.htc_cadence}'
        intervals-out: =steps.ms-info.num_intervals / recipe.htc_cadence
        nchan: 1
        niter: 0
        weight: '{recipe.htc_weight}'
        size: '{recipe.htc_size}'
        scale: '{recipe.htc_scale}'
        reorder: true
      tags: [lightcurves]
      skip_if_outputs: fresh

    htc-stack-1:
      info: |
        Stack a series of images into a single cube.
      cab: stack_time_cube
      params:
        images: =steps.htc-image*.dirty.per-interval
        cube: =DIRNAME(recipe.image-prefix) + '-cad{recipe.htc_cadence}/cube-{recipe.htc_cadence}-dirty.fits'
        ms: =recipe.ms
        cadence: =recipe.htc_cadence
      skip_if_outputs: fresh
      tags: [lightcurves]

    extract-metadata:
      info: |
        Run some custom python code to extract fits metadata from images.
      cab: extract_fits_metadata
      params:
        images: =previous.images
        timestamps_file: =STRIPEXT(previous.cube) + '.timestamps.p'
        beams_file: =STRIPEXT(previous.cube) + '.beams.p'
      skip_if_outputs: fresh
      tags: [lightcurves]

    cube-convolve:
      info: |
        Colvolve the image cube with a three dimensitional Gaussian filter.
        The extent of this filter in the spatial axes should be consistent
        with the restoring beam, and the time extent of the time axis should
        be matched to the temporal extent of features of interest.
      cab: convolve_image
      params:
        image: =steps.htc-stack-1.cube
        size_arcsec: =recipe.convolve.arcsec
        size_sec: =recipe.convolve.time
        outimage: =STRIPEXT(current.image) + '{recipe.lc-suffix}.fits'
      skip: =not recipe.lc-suffix
      skip_if_outputs: fresh
      tags: [lightcurves]

    extract-lightcurves:
      info: |
        Extract lightcurves from an image cube at the locations given by a
        catalog.
      skip: =not recipe.lc-suffix # skip if lc-suffix is not set: we don't make a convolved cube then
      cab: extract_lightcurves
      params:
        cube: =IF(recipe.lc-suffix, steps.cube-convolve.outimage, steps.htc-stack-1.cube)
        outdir: '{recipe.dir-out}/lc{recipe.htc_cadence}{recipe.lc-suffix}'
        catalog: =steps.make-master-catalog.master_catalog
        regfile: '{current.outdir}/lc{recipe.htc_cadence}-{recipe.obs}.reg'
        statsfile: '{current.outdir}/lc{recipe.htc_cadence}-{recipe.obs}.stats.p'
        output_file_label: "-{recipe.obs}"
        srctype: P
        minflux: 3uJy
        flag_excess_std: 3
        within: =recipe.lightcurves-within
        nsrc: 50000
        ncpu: 1  #=root.ncpu
        fluxcols: =recipe.catalog-flux-columns
        plot_title: =IF(recipe.publish-plots, NOSUBST(recipe.publish-plot-title), UNSET)
      skip_if_outputs: fresh
      tags: [lightcurves]

    extract-lightcurves-1:
      info: |
        Extracts lightcurves from the raw (unconvolved) cube.
      _use: lightcurve-pipeline.steps.extract-lightcurves
      skip: false
      params:
        cube: =steps.htc-stack-1.cube
        outdir: '{recipe.dir-out}/lc{recipe.htc_cadence}'
      skip_if_outputs: fresh
      tags: [lightcurves]
